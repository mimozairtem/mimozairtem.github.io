# Blog Post 2


This blog post will describe how to write a web scraper. I will demonstrate with several steps how to set up the project.

github repository: https://github.com/mimozairtem/blogpost_2

The web scraper will navigate through several pages and demonstrate a table that includes 2 columsn with the movie name and the number of shared actors.


The IMDB scraper will start at the Tv Show "Friends"' IMDB website. We will first have to import the package `scrapy` and define a IMDBSpider class to scrape.


`import scrapy`

`class ImdbSpider(scrapy.Spider):`



### First parse method: parse(self,response)

We will name the spider and add the url of the IMDB page we are starting at:
    

```
name = 'imdb-spider'
    
start_urls = ['https://www.imdb.com/title/tt0108778/']
```



Then, we will implement our first parse method:

```
def parse(self, response):
"""
This parse method starts at the movie or TV show's IMDB page.
Defines a cast_page that responds to the cast&crew page of the movie/TV-show.
If the cast_page exists, this url will be added to the starting url and will yield a scrapy.Request, calling back the parse_full_credits method.
"""
    #navigating to the cast&crew page with CSS selectors
    cast_page = response.css("div.ipc-title__wrapper a").attrib["href"]

    #if the cast page exists
    if cast_page:
        #add the cast page url to the original url
        cast_page = response.urljoin(cast_page) 
        
        #calls the next parse method without returning anything
        yield scrapy.Request(cast_page, callback = self.parse_full_credits)
            
````


This parse method starts at the IMDB page of the TV show and then navigates to the Cast and Crew page. Then, the second parse method parse_full_credits is called.

### Second parse method: parse_full_credits(self,response)


This parse method starts at the Cast&Crew page of the TV Show and yields a scrapy. Request for the page of the actor listed on the Crew members list. 


```
def parse_full_credits(self,response):
"""
This parse method starts at the cast&crew page fo the movie or TV show's IMDB page.
Defines a cast_photo_page that responds to the each cast's photo corrosponding to their page on IMDB.
If the cast_photo_page exists, this url will be added to the starting url and will yield a scrapy.Request, calling back the parse_actor_page method.
"""
    #navigating to the cast photo page with CSS selectors
    cast_photo_page = [a.attrib["href"] for a in response.css("td.primary_photo a")]
        
    #if url is in cast photo page 
    if cast_photo_page:
        for url in cast_photo_page:
        
            #add the cast photo page url to the original url
            cast_photo = response.urljoin(url)
            
            #calls the next parse method but does not return anything
            yield scrapy.Request(cast_photo, callback= self.parse_actor_page)
```

This method does not return any data but rather calls the method parse_actor_page.

### Third parse method: parse_actor_page(self,response)

The third parse method parse_actor_page 's main purpose is to yield two key-value pairs according to the actor page. The dictionary includes the actor's name and the movie or TV shows the actor has worked for. 

``` 
def parse_actor_page(self, response):

"""
This parse method defines a actor_name and movie_or_TV_name that yields a dictionary corresponding to the actor's name and the movie/TV show they appeared on.
This method returns a dictionary.
"""
    #navigating to the actor page with CSS selectors
    actor_name = response.css("span.itemprop::text").get()
        
    #navigating to the film page with CSS selectors    
    for film in response.css("div.filmo-category-section"):
    
        #select the movie or TV name with CSS selectors
        movie_or_TV_name = film.css("div.filmo-row a::text").get()

        #yields a dictionary according to actor and movie/TV name
        yield {
           "actor_name" : actor_name,
           "movie_or_TV_name" : movie_or_TV_name
            }
```

After writing these methods we should run the command :

`scrapy crawl imdb_spider -o results.csv`

### Demonstration of Results

This will create a csv file with a table, which includes two columns with the actor's name and the movie or TV shows the actor has played in. 

We will use this csv file to create a sorted list with the movie names and the number of shared actors for each movie.

After using this data to create a table we can use plotly or matplotlib to display the results.


```python
import pandas as pd
```


```python
df = pd.read_csv("results.csv")
```


```python
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>actor_name</th>
      <th>movie_or_TV_name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Reg Rogers</td>
      <td>The Blacklist</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Reg Rogers</td>
      <td>The Wedding Weekend</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Reg Rogers</td>
      <td>Broadway.com #LiveatFive</td>
    </tr>
    <tr>
      <th>3</th>
      <td>George Newbern</td>
      <td>Father of the Bride Part 3 (ish)</td>
    </tr>
    <tr>
      <th>4</th>
      <td>George Newbern</td>
      <td>Specifically</td>
    </tr>
  </tbody>
</table>
</div>




```python
s = df.groupby("actor_name")["movie_or_TV_name"].count().reset_index()
```


```python
s.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>actor_name</th>
      <th>movie_or_TV_name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Adam Goldberg</td>
      <td>12</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Al Collado</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Alison La Placa</td>
      <td>5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Angelika Roberts</td>
      <td>5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Bernard Curioso</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
s.rename(columns={"actor_name":"Actor Name", "movie_or_TV_name":"Number of Movie/TV Shows"}, inplace=True)
```


```python
s.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Actor Name</th>
      <th>Number of Movie/TV Shows</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Adam Goldberg</td>
      <td>12</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Al Collado</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Alison La Placa</td>
      <td>5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Angelika Roberts</td>
      <td>5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Bernard Curioso</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>


