# Blog Post 2


This blog post will describe how to write a web scraper. I will demonstrate with several steps how to set up the project.

The web scraper will navigate through several pages and demonstrate a table that includes 2 columsn with the movie name and the number of shared actors.


The IMDB scraper will start at the Tv Show "Friends"' IMDB website. We will first have to import the package `scrapy` and define a IMDBSpider class to scrape.


`import scrapy`

`class ImdbSpider(scrapy.Spider):`



### First parse method: parse(self,response)

We will name the spider and add the url of the IMDB page we are starting at:
    

```
name = 'imdb-spider'
    
start_urls = ['https://www.imdb.com/title/tt0108778/']
```



Then, we will implement our first parse method:

```
def parse(self, response):
"""
This parse method starts at the movie or TV show's IMDB page.
Defines a cast_page that responds to the cast&crew page of the movie/TV-show.
If the cast_page exists, this url will be added to the starting url and will yield a scrapy.Request, calling back the parse_full_credits method.
"""
        cast_page = response.css("div.ipc-title__wrapper a").attrib["href"]

        if cast_page:
            cast_page = response.urljoin(cast_page) 
            yield scrapy.Request(cast_page, callback = self.parse_full_credits)
            
````


This parse method starts at the IMDB page of the TV show and then navigates to the Cast and Crew page. Then, the second parse method parse_full_credits is called.

### Second parse method: parse_full_credits(self,response)


This parse method starts at the Cast&Crew page of the TV Show and yields a scrapy. Request for the page of the actor listed on the Crew members list. 


```
def parse_full_credits(self,response):
"""
This parse method starts at the cast&crew page fo the movie or TV show's IMDB page.
Defines a cast_photo_page that responds to the each cast's photo corrosponding to their page on IMDB.
If the cast_photo_page exists, this url will be added to the starting url and will yield a scrapy.Request, calling back the parse_actor_page method.
"""

        cast_photo_page = [a.attrib["href"] for a in response.css("td.primary_photo a")]
        if cast_photo_page:
            cast_photo_page = response.urljoin(cast_photo_page)
            yield scrapy.Request(cast_photo_page, callback= self.parse_actor_page)
```

This method does not return any data but rather calls the method parse_actor_page.

### Third parse method: parse_actor_page(self,response)

The third parse method parse_actor_page 's main purpose is to yield two key-value pairs according to the actor page. The dictionary includes the actor's name and the movie or TV shows the actor has worked for. 

``` 
def parse_actor_page(self, response):

"""
This parse method defines a actor_name and movie_or_TV_name that yields a dictionary corresponding to the actor's name and the movie/TV show they appeared on.
This method returns a dictionary.
"""
     for actor_name in response.css("td.name-overview-widget__section"):
         actor = actor_name.css("span.itemprop::text").get()
         yield {
            "actor" : actor 
          } 

    for film in response.css("div.filmo-category-section"):
        movie_or_TV_name = film.css("div.filmo-row a::text").get()

        yield {
        "movie_or_TV_name" : movie_or_TV_name
        }
```

After writing these methods we should run the command :

`scrapy crawl imdb_spider -o results.csv`

### Demonstration of Results

This will create a csv file with a table, which includes two columns with the actor's name and the movie or TV shows the actor has played in. 

We will use this csv file to create a sorted list with the movie names and the number of shared actors for each movie.

After using this data to create a table we can use plotly or matplotlib to display the results.

(My spider didn't print the results file, therefore, I couldn't include the table or the visual chart.)


```python

```
