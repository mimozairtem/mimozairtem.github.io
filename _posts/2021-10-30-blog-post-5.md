---
layout: post
title: Blog Post 5 

---


In Blog Post 5, we will focus on tensorflow datasets, data augmentation and transfer learning.

We will teach a machine learning algorithm how to distinguish between images of dogs and cats. 

First of all, we will import the necessary packages related to our blog post.


```python
import os
import tensorflow as tf
from tensorflow.keras import utils, datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np
```

# Load Packages and Obtain Data

Now, we will create tensorflow datasets for training, validation, and testing. We have used `image_dataset_from_directory` function from the keras package for this purpose. We are getting the data from the directory but the data is in random order according to the parameter `shuffle` inside the function. The parameter `batch_size` tells us how many data points are collected from the directory, here we can say that 32 pictures are gathered from each data set. 


```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
```

    Found 2000 files belonging to 2 classes.
    Found 1000 files belonging to 2 classes.


### Working with Datasets- Function

We will create a function called `visual_plot`


```python
def visual_plot(train_dataset):
  class_names = train_dataset.class_names
  image = []
  label = []

#take one batch from the train_dataset
  for images, labels in train_dataset.take(1):
    image.append(images)
    label.append(labels)


#loop over the images and append the image to 
#the corresponding element, either cats or dogs
  cats = []
  dogs = []
  for i in range(len(images)):
    temp = [0, 0]
    temp[0] = image[0][i].numpy().astype("uint8")
    temp[1] = class_names[label[0][i]]
    #append to list dogs
    if temp[1] == 'dogs' and len(dogs) < 3:
      dogs.append(temp)
    #append to list cats
    elif temp[1] == 'cats' and len(cats) < 3:
      cats.append(temp)

    if len(dogs) == 3 and len(cats) == 3:
      break

  #first row cats
  plt.figure(figsize=(10, 10))
  for i in range(len(cats)):
      plt.subplot(2,3,i+1)
      plt.imshow(cats[i][0])
      plt.title(cats[i][1])
      plt.axis("off")
  #second row dogs
  for i in range(len(dogs)):
      plt.subplot(2,3,i+4)
      plt.imshow(dogs[i][0])
      plt.title(dogs[i][1])
      plt.axis("off")

  plt.show()
```


```python
visual_plot(train_dataset)
```


    
![png](/images/output_10_0.png)
    



```python
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)

```

### Check Label Frequencies


```python
labels_iterator= train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()

```

Here, we are creating a iterater called labels to compute the number of images in the training data. The iterater will help us identify that "0" corresponds to `cats` and "1" corresponds to `dogs`.


```python
for labels in train_dataset.take(1):
  print(len(labels[1]))
```

    32


Here we can see that the total number of dogs and cats are 32.


```python
count = np.count_nonzero(labels[1] == 0)
print('Total occurences of cats in array: ', count)
```

    Total occurences of cats in array:  12



```python
count = np.count_nonzero(labels[1] == 1)
print('Total occurences of dogs in array: ', count)
```

    Total occurences of dogs in array:  20


According to the training data, there are 15 images of cats and 17 images of dogs in one batch of the training data.

# First Model

Here, we will create a `tf.keras.Sequential` model using different layers. 


```python
model1 = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Dropout(0.2),
    layers.Flatten(),
    layers.Dense(2),
])
```


```python
model1.summary()
```

    Model: "sequential"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     conv2d (Conv2D)             (None, 158, 158, 32)      896       
                                                                     
     max_pooling2d (MaxPooling2D  (None, 79, 79, 32)       0         
     )                                                               
                                                                     
     conv2d_1 (Conv2D)           (None, 77, 77, 32)        9248      
                                                                     
     max_pooling2d_1 (MaxPooling  (None, 38, 38, 32)       0         
     2D)                                                             
                                                                     
     conv2d_2 (Conv2D)           (None, 36, 36, 64)        18496     
                                                                     
     dropout (Dropout)           (None, 36, 36, 64)        0         
                                                                     
     flatten (Flatten)           (None, 82944)             0         
                                                                     
     dense (Dense)               (None, 2)                 165890    
                                                                     
    =================================================================
    Total params: 194,530
    Trainable params: 194,530
    Non-trainable params: 0
    _________________________________________________________________



```python
model1.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model1.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 6s 80ms/step - loss: 0.1412 - accuracy: 0.9680 - val_loss: 7.2520 - val_accuracy: 0.5483
    Epoch 2/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.1006 - accuracy: 0.9660 - val_loss: 6.5014 - val_accuracy: 0.5408
    Epoch 3/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.0845 - accuracy: 0.9755 - val_loss: 6.1969 - val_accuracy: 0.5235
    Epoch 4/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.1464 - accuracy: 0.9720 - val_loss: 6.9973 - val_accuracy: 0.5681
    Epoch 5/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.0983 - accuracy: 0.9785 - val_loss: 5.8483 - val_accuracy: 0.5718
    Epoch 6/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.0454 - accuracy: 0.9860 - val_loss: 7.0795 - val_accuracy: 0.5545
    Epoch 7/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.0969 - accuracy: 0.9785 - val_loss: 5.8856 - val_accuracy: 0.5483
    Epoch 8/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.0713 - accuracy: 0.9790 - val_loss: 6.6725 - val_accuracy: 0.5693
    Epoch 9/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.0720 - accuracy: 0.9825 - val_loss: 6.2858 - val_accuracy: 0.5483
    Epoch 10/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.0827 - accuracy: 0.9815 - val_loss: 6.1406 - val_accuracy: 0.5458
    Epoch 11/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.0811 - accuracy: 0.9780 - val_loss: 6.7141 - val_accuracy: 0.5507
    Epoch 12/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.0490 - accuracy: 0.9845 - val_loss: 7.4263 - val_accuracy: 0.5718
    Epoch 13/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.0734 - accuracy: 0.9805 - val_loss: 5.9961 - val_accuracy: 0.5606
    Epoch 14/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.0701 - accuracy: 0.9805 - val_loss: 6.2155 - val_accuracy: 0.5582
    Epoch 15/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.0353 - accuracy: 0.9900 - val_loss: 7.1558 - val_accuracy: 0.5644
    Epoch 16/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.0380 - accuracy: 0.9855 - val_loss: 6.9773 - val_accuracy: 0.5470
    Epoch 17/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.0951 - accuracy: 0.9860 - val_loss: 6.7441 - val_accuracy: 0.5421
    Epoch 18/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.2810 - accuracy: 0.9570 - val_loss: 5.5510 - val_accuracy: 0.5582
    Epoch 19/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.1258 - accuracy: 0.9700 - val_loss: 5.4260 - val_accuracy: 0.5582
    Epoch 20/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.0656 - accuracy: 0.9810 - val_loss: 5.5959 - val_accuracy: 0.5705



```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f92b0420e10>




    
![png](/images/output_25_1.png)
    


**The accuracy of my model stabilized between 54% and 57% during training.**

Overfitting can be observed in `model1`because the training accuracy is much higheer than the validation accuracy.

# Model with Data Augmentation

Here, we will add data augmentation layers to our model. This means that we are adding tranformations to the training images. For example, we changing the angle an image is shown in the dataset. 

We will create a `tf.keras.layers.RandomFlip()` layer to perform the data augmentation. 

### Random Flip:


```python
data_augmentation = tf.keras.Sequential([
  tf.keras.layers.RandomFlip('vertical')
])
```


```python
for image, _ in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  first_image = image[0]
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))
    plt.imshow(augmented_image[0] / 255)
    plt.axis('off')
```


    
![png](/images/output_33_0.png)
    


### Random Rotation


```python
data_augmentation = tf.keras.Sequential([
 tf.keras.layers.RandomRotation(0.3)
])
```


```python
for image, _ in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  first_image = image[0]
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))
    plt.imshow(augmented_image[0] / 255)
    plt.axis('off')
```


    
![png](/images/output_36_0.png)
    


#### Model 2:


```python
model2 = models.Sequential([
    layers.RandomRotation(0.3, input_shape=(160, 160, 3)),
    layers.RandomFlip('vertical'),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Dropout(0.2),
    layers.Flatten(),
    layers.Dense(2),
])
```


```python
model2.summary()
```

    Model: "sequential_3"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     random_rotation_1 (RandomRo  (None, 160, 160, 3)      0         
     tation)                                                         
                                                                     
     random_flip_1 (RandomFlip)  (None, 160, 160, 3)       0         
                                                                     
     conv2d_3 (Conv2D)           (None, 158, 158, 32)      896       
                                                                     
     max_pooling2d_2 (MaxPooling  (None, 79, 79, 32)       0         
     2D)                                                             
                                                                     
     conv2d_4 (Conv2D)           (None, 77, 77, 32)        9248      
                                                                     
     max_pooling2d_3 (MaxPooling  (None, 38, 38, 32)       0         
     2D)                                                             
                                                                     
     conv2d_5 (Conv2D)           (None, 36, 36, 64)        18496     
                                                                     
     dropout_1 (Dropout)         (None, 36, 36, 64)        0         
                                                                     
     flatten_1 (Flatten)         (None, 82944)             0         
                                                                     
     dense_1 (Dense)             (None, 2)                 165890    
                                                                     
    =================================================================
    Total params: 194,530
    Trainable params: 194,530
    Non-trainable params: 0
    _________________________________________________________________



```python
model2.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model2.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 6s 81ms/step - loss: 19.4607 - accuracy: 0.5205 - val_loss: 0.7031 - val_accuracy: 0.5334
    Epoch 2/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6987 - accuracy: 0.5125 - val_loss: 0.6892 - val_accuracy: 0.5297
    Epoch 3/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6991 - accuracy: 0.5150 - val_loss: 0.6936 - val_accuracy: 0.5470
    Epoch 4/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.6922 - accuracy: 0.5270 - val_loss: 0.6949 - val_accuracy: 0.5520
    Epoch 5/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.6920 - accuracy: 0.5215 - val_loss: 0.6888 - val_accuracy: 0.5606
    Epoch 6/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.6910 - accuracy: 0.5280 - val_loss: 0.7099 - val_accuracy: 0.5347
    Epoch 7/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6901 - accuracy: 0.5265 - val_loss: 0.6910 - val_accuracy: 0.5421
    Epoch 8/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6934 - accuracy: 0.5195 - val_loss: 0.6917 - val_accuracy: 0.5285
    Epoch 9/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.6933 - accuracy: 0.5120 - val_loss: 0.6911 - val_accuracy: 0.5272
    Epoch 10/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.6896 - accuracy: 0.5260 - val_loss: 0.6920 - val_accuracy: 0.5161
    Epoch 11/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.6913 - accuracy: 0.5235 - val_loss: 0.6902 - val_accuracy: 0.5371
    Epoch 12/20
    63/63 [==============================] - 5s 78ms/step - loss: 0.6896 - accuracy: 0.5185 - val_loss: 0.6916 - val_accuracy: 0.5371
    Epoch 13/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.6907 - accuracy: 0.5175 - val_loss: 0.6906 - val_accuracy: 0.5272
    Epoch 14/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.6880 - accuracy: 0.5455 - val_loss: 0.6903 - val_accuracy: 0.5408
    Epoch 15/20
    63/63 [==============================] - 5s 78ms/step - loss: 0.6917 - accuracy: 0.5060 - val_loss: 0.6936 - val_accuracy: 0.5186
    Epoch 16/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6899 - accuracy: 0.5175 - val_loss: 0.6918 - val_accuracy: 0.5260
    Epoch 17/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.6895 - accuracy: 0.5210 - val_loss: 0.6943 - val_accuracy: 0.5322
    Epoch 18/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.6890 - accuracy: 0.5250 - val_loss: 0.6914 - val_accuracy: 0.5384
    Epoch 19/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.6867 - accuracy: 0.5350 - val_loss: 0.7009 - val_accuracy: 0.5297
    Epoch 20/20
    63/63 [==============================] - 5s 78ms/step - loss: 0.6886 - accuracy: 0.5280 - val_loss: 0.6938 - val_accuracy: 0.5173



```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f92b05882d0>




    
![png](/images/output_41_1.png)
    


**The accuracy of model2 stabilized between 63% and 66% during training.**

The validation accuracy of model2 is higher than model1. 

The training accuracy is similar to the validation accuracy, therefore, we do not observe overfitting.

# Data Preprocessing

Here, we will create another layer called `preprocessor` which will scale the weights of our data prior to the training process. Therefore, we will not need to spend more energy on scaling the data.


```python
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])
```


```python
model3 = models.Sequential([
    preprocessor,                      
    layers.RandomRotation(0.3, input_shape=(160, 160, 3)),
    layers.RandomFlip('vertical'),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Dropout(0.2),
    layers.Flatten(),
    layers.Dense(2),
])
```


```python
model3.summary()
```

    Model: "sequential_4"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     model (Functional)          (None, 160, 160, 3)       0         
                                                                     
     random_rotation_2 (RandomRo  (None, 160, 160, 3)      0         
     tation)                                                         
                                                                     
     random_flip_2 (RandomFlip)  (None, 160, 160, 3)       0         
                                                                     
     conv2d_6 (Conv2D)           (None, 158, 158, 32)      896       
                                                                     
     max_pooling2d_4 (MaxPooling  (None, 79, 79, 32)       0         
     2D)                                                             
                                                                     
     conv2d_7 (Conv2D)           (None, 77, 77, 32)        9248      
                                                                     
     max_pooling2d_5 (MaxPooling  (None, 38, 38, 32)       0         
     2D)                                                             
                                                                     
     conv2d_8 (Conv2D)           (None, 36, 36, 64)        18496     
                                                                     
     dropout_2 (Dropout)         (None, 36, 36, 64)        0         
                                                                     
     flatten_2 (Flatten)         (None, 82944)             0         
                                                                     
     dense_2 (Dense)             (None, 2)                 165890    
                                                                     
    =================================================================
    Total params: 194,530
    Trainable params: 194,530
    Non-trainable params: 0
    _________________________________________________________________



```python
model3.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model3.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.7113 - accuracy: 0.5370 - val_loss: 0.6622 - val_accuracy: 0.5792
    Epoch 2/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6518 - accuracy: 0.6090 - val_loss: 0.6247 - val_accuracy: 0.6423
    Epoch 3/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.6418 - accuracy: 0.6240 - val_loss: 0.6121 - val_accuracy: 0.6745
    Epoch 4/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.6400 - accuracy: 0.6350 - val_loss: 0.6402 - val_accuracy: 0.6473
    Epoch 5/20
    63/63 [==============================] - 5s 78ms/step - loss: 0.6172 - accuracy: 0.6505 - val_loss: 0.6053 - val_accuracy: 0.6547
    Epoch 6/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.6025 - accuracy: 0.6780 - val_loss: 0.6067 - val_accuracy: 0.6807
    Epoch 7/20
    63/63 [==============================] - 5s 78ms/step - loss: 0.5682 - accuracy: 0.7035 - val_loss: 0.6294 - val_accuracy: 0.6646
    Epoch 8/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.5607 - accuracy: 0.7100 - val_loss: 0.6210 - val_accuracy: 0.6856
    Epoch 9/20
    63/63 [==============================] - 5s 78ms/step - loss: 0.5696 - accuracy: 0.7080 - val_loss: 0.6008 - val_accuracy: 0.6720
    Epoch 10/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.5488 - accuracy: 0.7165 - val_loss: 0.6200 - val_accuracy: 0.6856
    Epoch 11/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.5414 - accuracy: 0.7305 - val_loss: 0.5967 - val_accuracy: 0.6832
    Epoch 12/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.5565 - accuracy: 0.7045 - val_loss: 0.6055 - val_accuracy: 0.6658
    Epoch 13/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.5457 - accuracy: 0.7185 - val_loss: 0.6065 - val_accuracy: 0.6869
    Epoch 14/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.5333 - accuracy: 0.7285 - val_loss: 0.6323 - val_accuracy: 0.6906
    Epoch 15/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.5436 - accuracy: 0.7270 - val_loss: 0.5794 - val_accuracy: 0.7166
    Epoch 16/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.5236 - accuracy: 0.7355 - val_loss: 0.5798 - val_accuracy: 0.7104
    Epoch 17/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.5208 - accuracy: 0.7330 - val_loss: 0.6377 - val_accuracy: 0.6856
    Epoch 18/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.5170 - accuracy: 0.7520 - val_loss: 0.6165 - val_accuracy: 0.7030
    Epoch 19/20
    63/63 [==============================] - 5s 78ms/step - loss: 0.5085 - accuracy: 0.7625 - val_loss: 0.5935 - val_accuracy: 0.7153
    Epoch 20/20
    63/63 [==============================] - 5s 78ms/step - loss: 0.5157 - accuracy: 0.7495 - val_loss: 0.5983 - val_accuracy: 0.7067



```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f92b05f97d0>




    
![png](/images/output_51_1.png)
    


**The accuracy of model3 stabilized between 69% and 71%.**

The validation accuracy of model3 is much higher than what we were able to obtain with model2. 

The training accuracy is similar to the validation accuracy, therefore, we do not observe overfitting.

# Transfer Learning

Here, we will create another model in order to use a pre-existing model for our task. We will access a pre-existing "base model", use it in our task and train that model.


```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])

```

    Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5
    9412608/9406464 [==============================] - 0s 0us/step
    9420800/9406464 [==============================] - 0s 0us/step



```python
model4 = models.Sequential([                    
    preprocessor,                      
    layers.RandomRotation(0.3, input_shape=(160, 160, 3)),
    layers.RandomFlip('vertical'),
    base_model_layer,
    layers.GlobalMaxPooling2D(),
    layers.Dropout(0.2),
    layers.Flatten(),
    layers.Dense(2),
])
```


```python
model4.summary()
```

    Model: "sequential_5"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     model (Functional)          (None, 160, 160, 3)       0         
                                                                     
     random_rotation_3 (RandomRo  (None, 160, 160, 3)      0         
     tation)                                                         
                                                                     
     random_flip_3 (RandomFlip)  (None, 160, 160, 3)       0         
                                                                     
     model_1 (Functional)        (None, 5, 5, 1280)        2257984   
                                                                     
     global_max_pooling2d (Globa  (None, 1280)             0         
     lMaxPooling2D)                                                  
                                                                     
     dropout_3 (Dropout)         (None, 1280)              0         
                                                                     
     flatten_3 (Flatten)         (None, 1280)              0         
                                                                     
     dense_3 (Dense)             (None, 2)                 2562      
                                                                     
    =================================================================
    Total params: 2,260,546
    Trainable params: 2,562
    Non-trainable params: 2,257,984
    _________________________________________________________________



```python
model4.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 11s 112ms/step - loss: 1.1730 - accuracy: 0.7360 - val_loss: 0.1975 - val_accuracy: 0.9406
    Epoch 2/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.6085 - accuracy: 0.8500 - val_loss: 0.1221 - val_accuracy: 0.9592
    Epoch 3/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.5641 - accuracy: 0.8585 - val_loss: 0.1062 - val_accuracy: 0.9653
    Epoch 4/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.4606 - accuracy: 0.8705 - val_loss: 0.0857 - val_accuracy: 0.9728
    Epoch 5/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.4909 - accuracy: 0.8740 - val_loss: 0.0674 - val_accuracy: 0.9765
    Epoch 6/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.4552 - accuracy: 0.8830 - val_loss: 0.0703 - val_accuracy: 0.9703
    Epoch 7/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.4461 - accuracy: 0.8790 - val_loss: 0.0804 - val_accuracy: 0.9691
    Epoch 8/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.3705 - accuracy: 0.8940 - val_loss: 0.0826 - val_accuracy: 0.9703
    Epoch 9/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.3583 - accuracy: 0.8975 - val_loss: 0.0795 - val_accuracy: 0.9728
    Epoch 10/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.2721 - accuracy: 0.9195 - val_loss: 0.0872 - val_accuracy: 0.9740
    Epoch 11/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.3329 - accuracy: 0.9065 - val_loss: 0.0762 - val_accuracy: 0.9740
    Epoch 12/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.2932 - accuracy: 0.9170 - val_loss: 0.0718 - val_accuracy: 0.9752
    Epoch 13/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.2735 - accuracy: 0.9115 - val_loss: 0.0684 - val_accuracy: 0.9740
    Epoch 14/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.3193 - accuracy: 0.9080 - val_loss: 0.1150 - val_accuracy: 0.9567
    Epoch 15/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.3102 - accuracy: 0.9105 - val_loss: 0.0964 - val_accuracy: 0.9653
    Epoch 16/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.2748 - accuracy: 0.9160 - val_loss: 0.0712 - val_accuracy: 0.9715
    Epoch 17/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.3720 - accuracy: 0.9030 - val_loss: 0.1138 - val_accuracy: 0.9629
    Epoch 18/20
    63/63 [==============================] - 6s 90ms/step - loss: 0.2682 - accuracy: 0.9100 - val_loss: 0.0818 - val_accuracy: 0.9691
    Epoch 19/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.2624 - accuracy: 0.9140 - val_loss: 0.0689 - val_accuracy: 0.9703
    Epoch 20/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.2848 - accuracy: 0.9140 - val_loss: 0.0803 - val_accuracy: 0.9691



```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f92453d82d0>




    
![png](/images/output_61_1.png)
    


**The accuracy of model4 stabilized between 95% and 97%.**

The validation accuracy of model4 is much higher than what we were able to obtain with model3.



The training accuracy is similar to the validation accuracy, therefore, we do not observe overfitting.

# Score on Test Data


```python
loss, accuracy = model4.evaluate(test_dataset)
print('Test accuracy :', accuracy)
```

    6/6 [==============================] - 1s 58ms/step - loss: 0.0898 - accuracy: 0.9635
    Test accuracy : 0.9635416865348816


The training accuracy is nearly the same as the test accuracy.
