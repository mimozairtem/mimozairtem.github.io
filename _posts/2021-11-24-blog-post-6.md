---
layout: post
title: Blog Post 6

---

This blog post will be about misinformation and in particular fake news. We will use a dataset from an article about this matter. We will develop a fake news classifer using tensorflow.

# Acquire Training Data


```python
import numpy as np
import pandas as pd
import tensorflow as tf
import re
import string
from tensorflow import keras

from tensorflow.keras import layers
from tensorflow.keras import losses

from tensorflow.keras.layers.experimental.preprocessing import TextVectorization
from tensorflow.keras.layers.experimental.preprocessing import StringLookup

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# for embedding viz
import plotly.express as px 
import plotly.io as pio
```


```python
train_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true"
df  = pd.read_csv(train_url)
```


```python
df[0:20]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>title</th>
      <th>text</th>
      <th>fake</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17366</td>
      <td>Merkel: Strong result for Austria's FPO 'big c...</td>
      <td>German Chancellor Angela Merkel said on Monday...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5634</td>
      <td>Trump says Pence will lead voter fraud panel</td>
      <td>WEST PALM BEACH, Fla.President Donald Trump sa...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17487</td>
      <td>JUST IN: SUSPECTED LEAKER and “Close Confidant...</td>
      <td>On December 5, 2017, Circa s Sara Carter warne...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>12217</td>
      <td>Thyssenkrupp has offered help to Argentina ove...</td>
      <td>Germany s Thyssenkrupp, has offered assistance...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5535</td>
      <td>Trump say appeals court decision on travel ban...</td>
      <td>President Donald Trump on Thursday called the ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>13616</td>
      <td>North Korea says successfully launches new ICB...</td>
      <td>North Korea successfully launched a new type o...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1707</td>
      <td>California lawmakers take anti-Trump stance as...</td>
      <td>SACRAMENTO, Calif.California lawmakers voted t...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>15299</td>
      <td>New Delhi declares emergency as toxic smog thi...</td>
      <td>NEW The Indian capital declared a pollution em...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>4049</td>
      <td>AUDIO: Hannity Has RACIST Meltdown, Wants To ...</td>
      <td>Nobody would have ever said this about any of ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9</th>
      <td>12166</td>
      <td>Forgetful ministers keep Mugabe's name alive a...</td>
      <td>Zimbabwe s Robert Mugabe may have been deposed...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>10</th>
      <td>22195</td>
      <td>EP #15: Patrick Henningsen LIVE – ‘Crisis of A...</td>
      <td>Join Patrick every Wednesday at Independent T...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>11</th>
      <td>6507</td>
      <td>Senator McCain says Russia hacking probe not i...</td>
      <td>Republican U.S. Senator John McCain said on Th...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>12</th>
      <td>6973</td>
      <td>Fed may face unnerving shake-up under Trump ad...</td>
      <td>Change at the Federal Reserve could come quick...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>13</th>
      <td>12823</td>
      <td>HEY #NFL…CAN YOU HEAR US NOW? Monday Night Foo...</td>
      <td>The #NFL has become a showcase for an anti-law...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>14</th>
      <td>3358</td>
      <td>Trump seeks legislative wins to cast off shado...</td>
      <td>President Donald Trump pressed Republican cong...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>15</th>
      <td>15796</td>
      <td>OBAMA’S FUNDAMENTAL TRANSFORMATION: Census Rec...</td>
      <td>Adios America Census: Record 51 million immigr...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>16</th>
      <td>16531</td>
      <td>JUDGE JEANINE PIRRO: “We’re tired of being lec...</td>
      <td>Next stop after BREXIT is the US! Judge Jeanin...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>17</th>
      <td>20842</td>
      <td>Danish Queen's husband Prince Henrik diagnosed...</td>
      <td>Denmark s Prince Henrik, the husband of Queen ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>18</th>
      <td>3543</td>
      <td>Trump’s Potential Pick For Labor Secretary PR...</td>
      <td>Throughout the campaign, many have tried defen...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>19</th>
      <td>18055</td>
      <td>May's party suspends two EU lawmakers over Bre...</td>
      <td>Britain s ruling Conservatives barred two of t...</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



After loading the csv file, we can start to read our dataset. The `title` column displays the title of the article, the `text` column displays the full article and the `fake` column indicates whether the article is fake or not, 0 being true and 1 being fake. 

# Make a Dataset

The function `make_dataset` will remove stopwords such as but, and, the from the text and title columns. The function will construct a tensorflow Dataset with two inputs, title and text, and one output, the fake column.


```python
import nltk
nltk.download('stopwords')
```

    [nltk_data] Downloading package stopwords to /root/nltk_data...
    [nltk_data]   Unzipping corpora/stopwords.zip.





    True




```python
from nltk.corpus import stopwords
stop = stopwords.words('english')
```


```python
def make_dataset(df):
  df["title"] = df["title"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))
  df["text"] = df["text"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))
  data = tf.data.Dataset.from_tensor_slices(
    (
        {
            "title" : df[["title"]], 
            "text" : df[["text"]]
        }, 
        {
            "fake" : df[["fake"]]
        }
    )
  )
  data.batch(100)
  return data
```


```python
data = make_dataset(df)
```


```python
data
```




    <TensorSliceDataset shapes: ({title: (1,), text: (1,)}, {fake: (1,)}), types: ({title: tf.string, text: tf.string}, {fake: tf.int64})>




```python
train_size = int(0.7*len(data))
val_size   = int(0.2*len(data))

train = data.take(train_size)
val   = data.skip(train_size).take(val_size)
test  = data.skip(train_size + val_size)
```


```python
len(train), len(val), len(test)
```




    (15714, 4489, 2246)



# Create Models

We will try to answer the question: `When detecting fake news, is it most effective to focus on only the title of the article, the full text of the article, or both?`


We will determine the input for our model. We will also specify the shape, name and dtype of our input.


```python
title_input = keras.Input(
    shape = (1,), 
    name = "title",
    dtype = "string"
)
```


```python
max_words = 2000
```

Next, we will write a pipeline for our title features. We will use different layers like `Embedding`.


```python
title_features = layers.Embedding(max_words, 1, name = "embedding")(title_input)
title_features = layers.Dropout(0.2)(title_features)
title_features = layers.GlobalAveragePooling1D()(title_features)
title_features = layers.Dropout(0.2)(title_features)
title_features = layers.Dense(32, activation='relu')(title_features)
```

Here, we will create the output for our model. The output layer has a name, which is `fake`, matcign the target data in the dataset.


```python
output = layers.Dense(10, name = "fake")(title_features)
```

We will create our model using `keras.Model`and specifying the input and output.


```python
model = keras.Model(
    inputs = title_input,
    outputs = output)
```

Using `model.summary()` we can see the inputs and shapes of our model.


```python
model.summary()
```

    Model: "model"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     title (InputLayer)          [(None, 1)]               0         
                                                                     
     embedding (Embedding)       (None, 1, 1)              2000      
                                                                     
     dropout (Dropout)           (None, 1, 1)              0         
                                                                     
     global_average_pooling1d (G  (None, 1)                0         
     lobalAveragePooling1D)                                          
                                                                     
     dropout_1 (Dropout)         (None, 1)                 0         
                                                                     
     dense (Dense)               (None, 32)                64        
                                                                     
     fake (Dense)                (None, 2)                 66        
                                                                     
    =================================================================
    Total params: 2,130
    Trainable params: 2,130
    Non-trainable params: 0
    _________________________________________________________________


The `plot_model` function enables us to visualize the process in which the model is created.


```python
keras.utils.plot_model(model)
```




    
![png](/images/output_29_0.png)
    



Now, we will compile and train our model. 


```python
model.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']
)
```


```python
#history = model.fit(train, 
#                   validation_data=val,
#                    epochs = 50)
```

We will create two other TensorFlow models to determien which feature is the most effective when trying to detect fake news. The secınd model only uses the article text as input. The last model uses both the article title and the article text as input.

We are trying to score 97% accuracy for our models. 

# Model Evaluation

We will use the best performing model to test it on unseen data. Therefore, we will read in the test data and convert it using the `make_dataset` function we created before. 


```python
test_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true"

```


```python
test_df  = pd.read_csv(test_url)
```


```python
test_data = make_dataset(test_df)
```

We will then evaluate our model on the data:


```python
#model.evaluate(test_data)
```

# Embeddding Visualization

Now, we will visualize our model according to the embedding our model learned. 


```python
weights = model.get_layer('embedding').get_weights()[0] 
```

We will use PCA (principal component analysis) to reduce the dimension in order to be able to visualize it. 


```python
from sklearn.decomposition import PCA
pca = PCA(n_components=1)
weights = pca.fit_transform(weights)
```

We will then use plotly express to visualize our embedding.


```python
import plotly.express as px 
#fig = px.scatter(embedding_df, 
#                 x = "x0", 
#                 y = "x1", 
#                 size = list(np.ones(len(embedding_df))),
#                 size_max = 2,
#                 hover_name = "fake")

#fig.show()
```


```python

```
